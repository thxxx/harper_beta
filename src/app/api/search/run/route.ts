import { geminiInference, xaiInference } from "@/lib/llm/llm";
import { supabase } from "@/lib/supabase";
import { NextRequest, NextResponse } from "next/server";
import { deduplicateAndScore, UI_END, UI_START } from "../utils";
import { ko } from "@/lang/ko";
import { logger } from "@/utils/logger";
import { updateRunStatus } from "../utils";
import { parseQueryWithLLM } from "../parse";
import { searchDatabase } from "../parse";

type RunRow = {
  id: string;
  query_id: string;
  criteria?: any | null; // jsonb
  sql_query?: string | null;
  query_text?: string | null;
};

export async function POST(req: NextRequest) {
  const body = await req.json();
  const { queryId, runId, pageIdx, userId } = body as {
    queryId?: string;
    runId?: string;
    pageIdx?: number;
    userId?: string;
  };
  logger.log("\nìš°ì„  ì—¬ê¸°ì„œ í˜¸ì¶œ : ", body, "\n\n");

  if (!queryId || !runId) {
    return NextResponse.json(
      { error: "Missing queryId/runId" },
      { status: 400 }
    );
  }

  const page = Number.isFinite(pageIdx) ? (pageIdx as number) : 0;
  const nextPageIdx = page + 1;

  // 1) Check cached page in runs_pages
  const { data: cachedPages, error: cpErr } = await supabase
    .from("runs_pages")
    .select("*")
    .eq("run_id", runId)
    .eq("page_idx", page)
    .order("created_at", { ascending: false });

  if (cpErr) {
    logger.log("runs_pages load error:", cpErr);
  }

  const cached = cachedPages?.[0];
  if (cached && cached.candidate_ids) {
    const candidateIds = cached.candidate_ids
      .slice(0, 10)
      .map((r: any) => r.id);
    return NextResponse.json(
      { nextPageIdx, results: candidateIds },
      { status: 200 }
    );
  }

  // 2) If no cached results and page > 0, check previous page to decide if we can "slice" without new search
  let offset = 0;
  let cachedCandidates: any[] = [];

  if (page > 0) {
    const { data: prevPages } = await supabase
      .from("runs_pages")
      .select("*")
      .eq("run_id", runId)
      .eq("page_idx", page - 1)
      .order("created_at", { ascending: false });

    const prev = prevPages?.[0];

    if (!prev || !prev.candidate_ids || prev.candidate_ids.length === 0) {
      return NextResponse.json({ nextPageIdx, results: [] }, { status: 200 });
    }

    const isLoadMore = (prev.candidate_ids.length + page * 10) % 50 === 0;

    if (!isLoadMore) {
      // Just slice next 10 from prev cached candidates
      const rest = prev.candidate_ids.slice(10);

      await supabase.from("runs_pages").insert({
        run_id: runId,
        page_idx: page,
        candidate_ids: rest,
      });

      return NextResponse.json(
        { nextPageIdx, results: rest.slice(0, 10).map((r: any) => r.id) },
        { status: 200 }
      );
    } else {
      // It's a 50 boundary - decide if we can still slice or need new search
      const rest = prev.candidate_ids.slice(10);
      const scoreSum = rest
        .slice(0, 10)
        .reduce((acc: number, curr: any) => acc + curr.score, 0);

      if (scoreSum >= 10) {
        await supabase.from("runs_pages").insert({
          run_id: runId,
          page_idx: page,
          candidate_ids: rest,
        });

        return NextResponse.json(
          { nextPageIdx, results: rest.slice(0, 10).map((r: any) => r.id) },
          { status: 200 }
        );
      } else {
        offset = 50;
        cachedCandidates = rest;
      }
    }
  }

  // 3) Load run (source of truth for raw_input_text / criteria / sql_query)
  const { data: run, error: rErr } = await supabase
    .from("runs")
    .select("id, query_id, query_text, criteria, sql_query")
    .eq("id", runId)
    .eq("query_id", queryId)
    .single();

  if (rErr || !run) {
    return NextResponse.json({ error: "Run not found" }, { status: 404 });
  }

  let query_text = run.query_text ?? "";
  // 5) Ensure criteria/sql_query exist on the run (create if missing)
  let criteria: string[] = Array.isArray(run.criteria)
    ? (run.criteria as any)
    : [];
  let sql_query: string | null = run.sql_query ?? null;

  // If criteria is stored as object {criteria:[],...} in jsonb, normalize here
  // Example: run.criteria = { criteria: [...], thinking: "...", rephrasing: "..." }
  if (!criteria.length && run.criteria && typeof run.criteria === "object") {
    const maybe = (run.criteria as any)?.criteria;
    if (Array.isArray(maybe)) criteria = maybe;
  }

  if (!sql_query) {
    await updateRunStatus(run.id, ko.loading.making_query);

    const parsedQuery = await parseQueryWithLLM(query_text, criteria, "");
    if (typeof parsedQuery !== "string") {
      await updateRunStatus(run.id, JSON.stringify(parsedQuery));
      return NextResponse.json(parsedQuery, { status: 404 });
    }

    sql_query = parsedQuery;
    await supabase
      .from("runs")
      .update({
        sql_query: sql_query,
      })
      .eq("id", run.id);
  }

  // 6) Run search
  const searchResults = await searchDatabase(
    query_text,
    criteria,
    page,
    run as RunRow,
    sql_query,
    50,
    offset
  );

  const oneScoreCount = searchResults.filter((r: any) => r.score === 1).length;
  const merged = deduplicateAndScore(searchResults, cachedCandidates);

  const defaultMsg = `ì „ì²´ í›„ë³´ìžë“¤ ì¤‘ ${searchResults.length}ëª…ì„ ì„ ì •í•˜ê³ , ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ”ì§€ ê²€ì‚¬í–ˆìŠµë‹ˆë‹¤. ${oneScoreCount}ëª…ì´ ëª¨ë“  ê¸°ì¤€ì„ ë§Œì¡±í–ˆìŠµë‹ˆë‹¤.
${UI_START}{"type": "search_result", "text": "ê²€ìƒ‰ ê²°ê³¼", "run_id": "${runId}"}${UI_END}`;

  const msg = await xaiInference(
    "grok-4-fast-reasoning",
    "You are a helpful assistant.",
    `ì°¾ìœ¼ë ¤ëŠ” ì‚¬ëžŒì€ ${run.query_text}ìž…ë‹ˆë‹¤.
  ì§€ê¸ˆ 1) ê²€ìƒ‰ ì¡°ê±´ì— ê±¸ë¦° ì‚¬ëžŒì€ ${merged.length}ëª…, ê¸°ì¤€ì€ ${criteria?.join(
      ", "
    )}ì¸ë° ê° ì‚¬ëžŒì˜ ì •ë³´ë¥¼ ì½ì–´ë³´ì•˜ì„ ë•Œ, 2) ëª¨ë“  ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ” ì‚¬ëžŒì€ ${oneScoreCount}ëª…ìž…ë‹ˆë‹¤.
  1) ê²€ìƒ‰ ì¡°ê±´ì€ ê²€ìƒ‰ì— ë§žëŠ” SQL ì¿¼ë¦¬ë¥¼ LLMì´ ìƒì„±í•œ ë’¤ DBì— ì‚¬ìš©í–ˆì„ ë•Œ ì¶œë ¥ëœ ê²°ê³¼ë¡œ, ìµœëŒ€ 50ëª…ìœ¼ë¡œ ì œí•œí–ˆìŠµë‹ˆë‹¤. 2) ëª¨ë“  ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ” ì‚¬ëžŒì€ ê° ì‚¬ëžŒë³„ë¡œ ë””í…Œì¼í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¨ í›„, ì§ì ‘ assistantê°€ ì½ì–´ë³´ê³  íŒë‹¨í•œ ê²°ê³¼ìž…ë‹ˆë‹¤.
  ì´ ë•Œ, ìœ ì €ì—ê²Œ ì¶œë ¥í•  ì•ˆë‚´ë©”ì„¸ì§€ë¥¼ ì§§ê²Œ ìž‘ì„±í•˜ì„¸ìš”.

  ì •ë³´: SQL ì¿¼ë¦¬ëŠ” LLMì´ ìž‘ì„±í•˜ê¸° ë•Œë¬¸ì— í•´ë‹¹ ë¶€ë¶„ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ë„ ìžˆë‹¤. limitì„ 50ìœ¼ë¡œ ê±¸ì—ˆê¸° ë•Œë¬¸ì— ê²€ìƒ‰ ì¡°ê±´ì— ê±¸ë¦°ê²Œ 50ëª…ì´ë¼ëŠ” ëœ»ì€, ì‹¤ì œë¡œ DBì—ëŠ” í•´ë‹¹ ì¿¼ë¦¬ë¥¼ ë§Œì¡±í•˜ëŠ”ê²Œ 50ëª… ì´ìƒì´ë¼ëŠ” ëœ»ì´ë‹¤. 
ìœ„ ì •ë³´ë¥¼ í•­ìƒ ìœ ì €ì—ê²Œ ë§í•˜ë¼ëŠ”ê±´ ì•„ë‹ˆê³ , í˜¹ì‹œ í•„ìš”í•˜ë©´ ì°¸ê³ í•´ë„ ë¨.
ì•„ëž˜ ê¸°ë³¸ ì¶œë ¥ ë©”ì„¸ì§€ëŠ” í•­ìƒ ìœ ì €ì—ê²Œ ë¦¬í„´ë˜ëŠ” ê°’ìœ¼ë¡œ, ì´ ë’¤ì— ì¶”ê°€ë¡œ ì¶œë ¥í•  ë‚´ìš©ë§Œ ìž‘ì„±í•˜ì„¸ìš”. ì ˆëŒ€ ê¸°ë³¸ ì¶œë ¥ ë©”ì„¸ì§€ë¥¼ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”.

ê¸°ë³¸ ì¶œë ¥ ë©”ì„¸ì§€: ${defaultMsg}`,
    0.7,
    1
  );
  logger.log("msg ======================== ", msg);

  const res1 = await supabase.from("messages").insert({
    query_id: queryId,
    user_id: userId,
    role: 1,
    content: defaultMsg + "\n" + msg,
  });
  logger.log("res1 ", res1);

  // 7) Cache candidates for this page into runs_pages
  const candidatesForCache = merged.map((r: any) => ({
    score: r.score,
    id: r.id,
  }));

  const { error: insErr } = await supabase.from("runs_pages").insert({
    run_id: runId,
    page_idx: page,
    candidate_ids: candidatesForCache,
  });

  if (insErr) logger.log("runs_pages insert error:", insErr);

  const candidateIds = candidatesForCache.slice(0, 10).map((r: any) => r.id);

  if (
    page === 0 &&
    (candidateIds.length === 0 ||
      candidateIds.length < 10 ||
      candidateIds.length >= 50 ||
      oneScoreCount <= 5)
  ) {
    // const message = await makeMessage(
    //   query_text,
    //   criteria?.join(", ") ?? "",
    //   candidateIds.length === 0
    //     ? "no"
    //     : candidateIds.length < 10
    //     ? "less"
    //     : "more"
    // );
  }

  // 9) Slack notify if nothing found on first page
  // if (page === 0 && candidateIds.length === 0) {
  //   await notifyToSlack(
  //     `ðŸ” *Search Result Not Found! ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì–´ìš”!*\n\n` +
  //       `â€¢ *Query*: ${query_text}\n` +
  //       `â€¢ *Criteria*: ${criteria?.join(", ")}\n` +
  //       `â€¢ *Run ID*: ${runId}\n` +
  //       `â€¢ *Time(Standard Korea Time)*: ${new Date().toLocaleString("ko-KR")}`
  //   );
  // }

  return NextResponse.json(
    { nextPageIdx, results: candidateIds, isNewSearch: true },
    { status: 200 }
  );
}
