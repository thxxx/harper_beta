import { supabase } from "@/lib/supabase";
import { NextRequest, NextResponse } from "next/server";
import OpenAI from "openai";

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// const testSql = `
// SELECT
//   to_json(T1.id) AS id,
//   T1.name,
//   T1.headline,
//   T1.location,
//   T1.publications,
//   T1.bio,
//   T1.linkedin_url,
//   T1.total_exp_months,
//   T1.links,
//   T1.profile_picture,
//   jsonb_agg(
//     DISTINCT jsonb_build_object(
//         'experience', jsonb_strip_nulls(to_jsonb(T2.*)),
//         'company', jsonb_strip_nulls(
//             jsonb_build_object(
//                 'logo', T3.logo,
//                 'name', T3.name
//             )
//         )
//     )
//   ) FILTER (WHERE T2.candid_id IS NOT NULL) AS experiences,
//   jsonb_agg(
//       DISTINCT jsonb_strip_nulls(to_jsonb(T4.*))
//   ) FILTER (WHERE T4.candid_id IS NOT NULL) AS educations
// FROM
//   candid AS T1
// INNER JOIN
//   experience_user AS T2 ON T1.id = T2.candid_id
// INNER JOIN
//   company_db AS T3 ON T2.company_id = T3.id
// INNER JOIN
//   edu_user AS T4 ON T1.id = T4.candid_id
// ${parsed_text}

// GROUP BY
//   T1.id
// `

async function parseQueryWithLLM(queryText: string): Promise<string> {
  const prompt = `
ÎÑàÎäî Ï±ÑÏö© ÌõÑÎ≥¥Ïûê Í≤ÄÏÉâÏùÑ ÏúÑÌïú **Ï†ÑÎ¨∏ SQL Query Parser**Îã§.
ÏûÖÎ†•ÏùÄ ÏûêÏó∞Ïñ¥Î°ú ÏûëÏÑ±Îêú Ï±ÑÏö© ÌõÑÎ≥¥Ïûê Í≤ÄÏÉâ ÏöîÏ≤≠Ïù¥Îã§.

ÎÑàÏùò Î™©ÌëúÎäî:
- Ïã§Ï†ú Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú **ÌõÑÎ≥¥ÏûêÍ∞Ä Ï∂©Î∂ÑÌûà ÎßéÏù¥ Îß§Ïπ≠ÎêòÎèÑÎ°ù**
- Ï°∞Í±¥ÏùÑ **ÎÑàÎ¨¥ Ï¢ÅÌûàÏßÄ ÎßêÍ≥†**, Ìï©Î¶¨Ï†ÅÏúºÎ°ú **ÌôïÏû•Îêú OR Ï°∞Í±¥**ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨
- Í≤ÄÏÉâ ÌíàÏßàÏù¥ Ï¢ãÏùÄ WHERE Ï†àÏùÑ ÏÉùÏÑ±ÌïòÎäî Í≤ÉÏù¥Îã§.

---

### üì¶ Database Schema

- T1: candid  
  - id (PK)
  - headline
  - bio
  - name
  - location

- T2: experience_user  
  - candid_id (FK ‚Üí candid.id)
  - role
  - description : Î≥∏Ïù∏Ïù¥ Ìïú ÏùºÏóêÎåÄÌïú ÏÑ§Î™Ö
  - start_date (DATE, format: YYYY-MM-DD)
  - end_date (DATE)
  - company_id (FK ‚Üí company_db.id)

- T3: company_db  
  - id (PK)
  - name
  - description : ÌöåÏÇ¨Ïóê ÎåÄÌïú ÏÑ§Î™Ö
  - employee_count_range
  - founded_year
  - website_url

- T4: education_user  
  - candid_id (FK ‚Üí candid.id)
  - school
  - degree
  - field
  - start_date (DATE)
  - end_date (DATE)

---

### üö® Ï∂úÎ†• Í∑úÏπô (Ï†àÎåÄ ÏúÑÎ∞ò Í∏àÏßÄ)

1. **Ï∂úÎ†•ÏùÄ Î∞òÎìúÏãú WHERE Î°ú ÏãúÏûëÌïòÎäî SQL Ï°∞Í±¥Î¨∏Îßå Î∞òÌôòÌïúÎã§**
   - SELECT, FROM, JOIN, ORDER BY, LIMIT Ìè¨Ìï® No
   - Ïò§ÏßÅ 'WHERE ...' Î≥∏Î¨∏Îßå Ï∂úÎ†•

2. **Ï†àÎåÄ ÏÇ¨Ïö© Í∏àÏßÄ SQL**
   - UPDATE No
   - DELETE No
   - INSERT No
   - DROP No

3. **Ï°∞Í±¥ ÌëúÌòÑ Î∞©Ïãù**
   - Î™®Îì† Ï°∞Í±¥ÏùÄ Î∞òÎìúÏãú 'ILIKE '%keyword%'' ÌòïÏãù ÏÇ¨Ïö©
   - Ï†ïÌôï ÏùºÏπò('='), Ï†ïÍ∑úÏãù('~'), full-text search No
   - Î∞òÎìúÏãú 'OR / AND' Ï°∞Ìï©ÏúºÎ°ú ÏûëÏÑ±

4. **Ïñ∏Ïñ¥ Í∑úÏπô**
   - Îç∞Ïù¥ÌÑ∞Îäî **ÎåÄÎ∂ÄÎ∂Ñ ÏòÅÏñ¥**Î°ú Ï†ÄÏû•ÎêòÏñ¥ ÏûàÏùå
   - ÌïúÍµ≠Ïñ¥ ÌÇ§ÏõåÎìúÎ•º ÏÇ¨Ïö©Ìï† Í≤ΩÏö∞:
     - Î∞òÎìúÏãú ÎåÄÏùëÎêòÎäî ÏòÅÏñ¥ ÌÇ§ÏõåÎìúÎ•º **Ìï®Íªò OR Ï°∞Í±¥ÏúºÎ°ú Ìè¨Ìï®**
     - (Ïòà: "ÏÑúÏö∏ÎåÄÌïôÍµê" ‚Üí "seoul national university", "SNU")

---

### üéØ Í≤ÄÏÉâ Ï†ÑÎûµ Í∞ÄÏù¥Îìú (Îß§Ïö∞ Ï§ëÏöî)

- Ï°∞Í±¥ÏùÑ **ÌïúÎëê Í∞úÎßå Ïì∞ÏßÄ ÎßêÍ≥†**, Î∞òÎìúÏãú **Ïó¨Îü¨ Í∞úÏùò ÌôïÏû•Îêú ÌÇ§ÏõåÎìú**Î•º ÏÇ¨Ïö©ÌïòÎùº
- ÎÑàÎ¨¥ ÌÉÄÏù¥Ìä∏Ìïú AND Ï°∞Í±¥ÏùÑ ÎÇ®Î∞úÌïòÏßÄ Îßê Í≤É
- Í∞ÄÎä•ÌïòÎ©¥ Îã§ÏùåÏùÑ Ï†ÅÍ∑π ÌôúÏö©ÌïòÎùº:
  - ÏßÅÎ¨¥ Ïú†ÏÇ¨Ïñ¥ (engineer / scientist / researcher / developer Îì±)
  - Ï†ÑÍ≥µ Ïú†ÏÇ¨Ïñ¥ (computer science / software / AI / ML / data Îì±)
  - ÌöåÏÇ¨ ÏÑ§Î™Ö(description) Í∏∞Î∞ò Í≤ÄÏÉâ
  - headline / bio / publications ÌôúÏö©

---

### üß† Ï°∞Í±¥ Ìï¥ÏÑù Í∞ÄÏù¥Îìú

- ÌïôÎ†• Ï°∞Í±¥ ‚Üí T4.school, T4.degree, T4.field
- ÏßÅÎ¨¥/Í≤ΩÎ†• ‚Üí T2.role, T2.description
- ÌöåÏÇ¨ ÌäπÏßï ‚Üí T3.name, T3.description
- Í∞úÏù∏ ÌÇ§ÏõåÎìú ‚Üí T1.headline, T1.bio, T1.publications, T1.location

---

### üìÖ ÎÇ†Ïßú Ï°∞Í±¥ (ÏÑ†ÌÉùÏ†Å)

- Í≤ΩÎ†• Ïó∞Ï∞®, ÏµúÍ∑º Í∑ºÎ¨¥ Ïó¨Î∂ÄÍ∞Ä Ìè¨Ìï®Îêú Í≤ΩÏö∞:
  - start_date / end_dateÏóê ÎåÄÌï¥
  - ÏßÅÏ†ë Í≥ÑÏÇ∞ÏùÄ ÌïòÏßÄ ÎßêÍ≥†, **Ïó∞ÎèÑ Î¨∏ÏûêÏó¥ Í∏∞Î∞ò ÌÇ§ÏõåÎìú Í≤ÄÏÉâÏùÄ Í∏àÏßÄ**
  - ÎÇ†Ïßú Ï°∞Í±¥Ïù¥ Ïï†Îß§ÌïòÎ©¥ **ÎÇ†Ïßú Ï°∞Í±¥ÏùÑ ÏÉùÎûµÌïòÍ≥† ÏßÅÎ¨¥ ÌÇ§ÏõåÎìúÎ°ú Î≥¥ÏôÑ**

---

### ‚úÖ Ï∂úÎ†• ÏòàÏãú

ÏûêÏó∞Ïñ¥ ÏûÖÎ†•:
> ÌïúÍµ≠ Top ÎåÄÌïô Ï∂úÏã†Ïù¥Î©¥ÏÑú AI Î¶¨ÏÑúÏ≤ò ÎòêÎäî Î®∏Ïã†Îü¨Îãù ÏóîÏßÄÎãàÏñ¥

Ï∂úÎ†•:
WHERE
(
  T4.school ILIKE '%seoul national university%'
  OR T4.school ILIKE '%SNU%'
  OR T4.school ILIKE '%ÏÑúÏö∏ÎåÄÌïôÍµê%'
  OR T4.school ILIKE '%yonsei university%'
  OR T4.school ILIKE '%Ïó∞ÏÑ∏ÎåÄÌïôÍµê%'
  OR T4.school ILIKE '%korea university%'
  OR T4.school ILIKE '%Í≥†Î†§ÎåÄÌïôÍµê%'
  OR T4.school ILIKE '%KAIST%'
  OR T4.school ILIKE '%postech%'
)
AND
(
  T4.field ILIKE '%computer%'
  OR T4.field ILIKE '%software%'
  OR T4.field ILIKE '%artificial intelligence%'
  OR T4.field ILIKE '%machine learning%'
)
OR
(
  T2.role ILIKE '%research%'
  OR T2.role ILIKE '%machine learning engineer%'
  OR T2.role ILIKE '%ml engineer%'
  OR T2.role ILIKE '%ai engineer%'
  OR T1.headline ILIKE '%research%'
)

---

### üì• ÏûÖÎ†•

Natural Language Query:
${queryText}

---

### ‚ö†Ô∏è ÎßàÏßÄÎßâ Í≤ΩÍ≥†

- ÏÑ§Î™Ö, Ï£ºÏÑù, ÏΩîÎìúÎ∏îÎ°ù, ÎßàÌÅ¨Îã§Ïö¥ Ï∂úÎ†• X
- SQL WHERE Ï†à **Î≥∏Î¨∏Îßå** Ï∂úÎ†•ÌïòÎùº
- Ìïú Ï§ÑÏù¥ÎùºÎèÑ Í∑úÏπôÏùÑ Ïñ¥Í∏∞Î©¥ Ïã§Ìå®Îã§
`.trim();

  // Responses API + structured outputs (text.format)
  const resp = await openai.responses.create({
    model: "gpt-4.1", // ÎÑà ÌôòÍ≤ΩÏóê ÎßûÍ≤å Ï°∞Ï†ï
    input: prompt,
  });

  // SDKÍ∞Ä Î∞òÌôòÌïòÎäî Íµ¨Ï°∞Îäî Î≤ÑÏ†ÑÏóê Îî∞Îùº Îã§Î•º Ïàò ÏûàÏñ¥,
  // ÏïÑÎûòÎäî "ÏµúÏ¢Ö ÌÖçÏä§Ìä∏(JSON)"Î•º Í∫ºÎÇ¥Îäî Î≥¥ÏàòÏ†ÅÏù∏ Î∞©Ïãù.
  const outText =
    resp.output_text ?? (resp as any).output?.[0]?.content?.[0]?.text ?? "";

  return outText;
}

export async function POST(req: NextRequest) {
  const body = await req.json();
  const { queryId, pageIdx } = body;
  console.log("ÏßÑÏûÖ ÌôïÏù∏ : ", queryId, pageIdx);

  if (!queryId)
    return NextResponse.json({ error: "Missing queryId" }, { status: 400 });

  const { data: q, error: qErr } = await supabase
    .from("queries")
    .select("query_id,user_id,raw_input_text,query")
    .eq("query_id", queryId)
    .single();

  console.log("ÏùºÎã® ÏøºÎ¶¨ ÌôïÏù∏ : ", q);

  if (qErr || !q || !q.raw_input_text)
    return NextResponse.json({ error: "Query not found" }, { status: 404 });

  const { data: results, error: lpErr } = await supabase
    .from("query_pages")
    .select("*")
    .eq("query_id", queryId)
    .eq("page_idx", pageIdx)
    .maybeSingle();

  console.log(pageIdx, "ÏøºÎ¶¨ÏôÄ results ", results, q);

  if (lpErr)
    return NextResponse.json({ error: lpErr.message }, { status: 500 });

  const nextPageIdx = pageIdx + 1;

  // Ï†ÄÏû•ÎêòÏñ¥ÏûàÎäî Í≤∞Í≥ºÍ∞Ä ÏóÜÎã§Î©¥ ÏÉàÎ°≠Í≤å Í≤ÄÏÉâÌï¥ÏïºÌïúÎã§Îäî Îúª.
  if (!results) {
    let parsed_query = q.query;
    if (!parsed_query) {
      parsed_query = await parseQueryWithLLM(q.raw_input_text);
      console.log("parsed_text ", parsed_query);

      const upsertRes = await supabase
        .from("queries")
        .upsert({ query_id: queryId, user_id: q.user_id, query: parsed_query });
      console.log("upsertRes ", upsertRes);
    }

    // LLMÏù¥ ÏÉùÏÑ±Ìï¥Ïïº ÌïòÎäî ÏïàÏ†ÑÌïú SQL ÏøºÎ¶¨ (ÏòàÏãú)
    const testSql = `
SELECT 
  to_json(T1.id) AS id,
  T1.name,
  T1.headline,
  T1.location,
  T1.publications,
  T1.bio,
  T1.linkedin_url,
  T1.total_exp_months,
  T1.links,
  T1.profile_picture,
  jsonb_agg(
    DISTINCT jsonb_build_object(
        'experience', jsonb_strip_nulls(to_jsonb(T2.*)),
        'company', jsonb_strip_nulls(
            jsonb_build_object(
                'logo', T3.logo,
                'name', T3.name
            )
        )
    )
  ) FILTER (WHERE T2.candid_id IS NOT NULL) AS experiences,
  jsonb_agg(
      DISTINCT jsonb_strip_nulls(to_jsonb(T4.*))
  ) FILTER (WHERE T4.candid_id IS NOT NULL) AS educations
FROM 
  candid AS T1
INNER JOIN 
  experience_user AS T2 ON T1.id = T2.candid_id
INNER JOIN 
  company_db AS T3 ON T2.company_id = T3.id
INNER JOIN
  edu_user AS T4 ON T1.id = T4.candid_id
${parsed_query}

GROUP BY 
  T1.id
`;

    const limit = 10;
    const { data, error } = await supabase.rpc(
      "set_timeout_and_execute_raw_sql",
      {
        sql_query: testSql,
        page_idx: pageIdx,
        limit_num: limit,
      }
    );

    console.log("Í∑∏ÎûòÏÑú Í≤ÄÏÉâÌïúÍ≤å Î≠îÎç∞? data ", data, error);
    if (!data)
      return NextResponse.json(
        { page_idx: pageIdx, results: [] },
        { status: 500 }
      );

    const buildSummary = (doc: any) => {
      const exps = doc.experiences?.map((exp: any) => {
        let expText = `Role: ${exp.role}, Company: ${exp.company.name}`;
        if (exp.start_date) {
          expText += `, Start Date: ${exp.start_date}`;
        }
        if (exp.end_date) {
          expText += `, End Date: ${exp.end_date}`;
        }

        return expText;
      });

      const educations = doc.educations?.map((edu: any) => {
        let eduText = `School: ${edu.school}, Degree: ${edu.degree}, Field: ${edu.field}`;
        if (edu.start_date) {
          eduText += `, Start Date: ${edu.start_date}`;
        }
        if (edu.end_date) {
          eduText += `, End Date: ${edu.end_date}`;
        }
        return eduText;
      });

      const publications = doc.publications
        ? JSON.stringify(doc.publications.slice(0, 5))
        : "";

      const bio = doc.bio ? doc.bio : "";
      return `
${doc.name} is a ${doc.location} based.
About: ${bio}
Headline: ${doc.headline}
Experiences: ${exps}
Educations: ${educations}
Publications: ${publications}`;
    };

    (data[0] as Array<any>)?.forEach(async (doc: any, index: number) => {
      const res_check = await supabase
        .from("synthesized_summary")
        .select("*")
        .eq("candid_id", doc.id)
        .eq("query_id", queryId)
        .maybeSingle();

      console.log("res_check ", res_check);

      if (!res_check.data) {
        const information = buildSummary(doc);

        const res = await openai.chat.completions.create({
          model: "gpt-4.1-nano",
          messages: [
            {
              role: "system",
              content:
                "You are a helpful assistant. Given a search query and a candidate profile, generate a relevance-focused summary explaining why this candidate matches the query. Use exactly three sentences. Highlight especially important skills, experiences, or keywords by wrapping them with <strong> tags. ÏòÅÏñ¥ Îã®Ïñ¥Í∞Ä Îì§Ïñ¥Í∞ÄÎäîÍ±¥ ÏÉÅÍ¥ÄÏóÜÎäîÎç∞, ÌïúÍ∏ÄÎ°ú ÎåÄÎãµÌï¥Ï§ò.",
            },
            {
              role: "user",
              content: `Search Query : ${q.raw_input_text} \n\n Information : ${information}`,
            },
          ],
        });
        const summary = res.choices[0].message.content;
        console.log("summary ", summary);

        const { error: insErr } = await supabase
          .from("synthesized_summary")
          .insert({
            candid_id: doc.id,
            query_id: queryId,
            text: summary,
          });
      } else {
      }

      // if (index === data[0].length - 1) {
      // }
    });

    const candidateIds = (data[0] as Array<any>)?.map((r: any) => r.id) ?? [];
    console.log("Í≤ÄÏÉâ Í≤∞Í≥º candidateIds ", candidateIds);

    const { error: insErr } = await supabase.from("query_pages").insert({
      query_id: queryId,
      page_idx: pageIdx,
      candidate_ids: candidateIds,
    });

    if (insErr)
      return NextResponse.json({ error: insErr.message }, { status: 500 });

    return NextResponse.json(
      { nextPageIdx, results: candidateIds },
      { status: 200 }
    );
  } else {
    return NextResponse.json(
      { nextPageIdx, results: results.candidate_ids },
      { status: 200 }
    );
  }
}
