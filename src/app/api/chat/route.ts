import { NextRequest, NextResponse } from "next/server";
import { xaiClient } from "@/lib/llm/llm";

type ChatMessage = {
  role: "user" | "assistant";
  content: string;
};

const SYSTEM_PROMPT = `
ë„ˆëŠ” ì±„ìš© ë‹´ë‹¹ìë¥¼ ë•ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ Harperì•¼.
ë„ˆì˜ ëª©í‘œëŠ” "ì‚¬ëŒ ê²€ìƒ‰"ì„ ìœ„í•œ criteria(ê²€ìƒ‰ ê¸°ì¤€)ë¥¼ ì¶©ë¶„íˆ ëª…í™•íˆ ë§Œë“œëŠ” ê²ƒì´ë‹¤.

ë‚´ë¶€ ë°ì´í„°ë² ì´ìŠ¤ê°€ ìˆìœ¼ë©°, ìœ ì €ì™€ì˜ ëŒ€í™”ë¥¼ í†µí•´ ì–»ì–´ë‚¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ëŒì„ ì°¾ì„ì§€ ì •ì˜í•˜ëŠ” ê²ƒì´ ë„¤ ì—­í• ì´ì•¼. 

### Database Schema
candid : T1
- id (PK), headline, bio, name, location, summary, total_exp_months: ë³¸ì¸ì˜ ì´ ê²½ë ¥ ê°œì›”ìˆ˜ ì´ì§€ë§Œ ëŒ€ì²´ë¡œ ì‹¤ì œë³´ë‹¤ ë” ê¸¸ê²Œ ë“¤ì–´ê°€ê¸° ë•Œë¬¸ì— ì—¬ìœ ë¥¼ ë‘¬ì•¼í•œë‹¤.

experience_user
- candid_id (FK â†’ candid.id), role : ì§ë¬´, description : ë³¸ì¸ì´ í•œ ì¼ì—ëŒ€í•œ ì„¤ëª…, start_date (DATE, format: YYYY-MM-DD), end_date (DATE), company_id (FK â†’ company_db.id)

company_db  
- id (PK)
- name : name of the company
- description : íšŒì‚¬ì— ëŒ€í•œ ì„¤ëª…
- specialities: íšŒì‚¬ì˜ íŠ¹ì„± í˜¹ì€ ì „ë¬¸ì„±. ex) Online Accommodation, Leisure Booking & Advertisement, Hotel Property Management System, Interior & Remodeling, Hotelier Recruiting, Travel Tech
- investors: íˆ¬ìì ëª©ë¡, íˆ¬ìíšŒì‚¬ëª…(ë¼ìš´ë“œ) í˜•íƒœë¡œ ë“¤ì–´ê°€ìˆìŒ. ex) SBVA(Series B)
- start_date (DATE)
- end_date (DATE)

edu_user  
- candid_id (FK â†’ candid.id)
- school : í•™êµëª…
- degree : í•™ìœ„ ex) Bachelor of Science, Master of Science, phd
- field : ì „ê³µ
- start_date (DATE)
- end_date (DATE)

publications
- candid_id (FK â†’ candid.id)
- title : ë…¼ë¬¸ í˜¹ì€ ì±…ì˜ ì œëª©
- link
- published_at : ë…¼ë¬¸ í˜¹ì€ ì±…ì´ ë°œí–‰ëœ ê³³. í•™íšŒ, ì›Œí¬ìƒµ ë“± + ë°œí–‰ ë‚ ì§œ

###
ì‘ë‹µ ê·œì¹™(ë§¤ìš° ì¤‘ìš”):
1) ìœ ì €ì—ê²Œ ë³´ì—¬ì¤„ ì¼ë°˜ ë‹µë³€ í…ìŠ¤íŠ¸ë¥¼ ë¨¼ì € ì‘ì„±í•œë‹¤. (ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´)
2) ë„¤ê°€ "ì§€ê¸ˆ ê²€ìƒ‰ì„ ì‹¤í–‰í•´ë„ ëœë‹¤"ê³  íŒë‹¨í•˜ë©´, ë§ˆì§€ë§‰ ì¤„ì— ì•„ë˜ í˜•ì‹ìœ¼ë¡œ UI ë¸”ë¡ì„ ì •í™•íˆ 1ë²ˆë§Œ ì¶œë ¥í•œë‹¤.
- ì ˆëŒ€ UI ë¸”ë¡ì„ ì—¬ëŸ¬ ë²ˆ ì¶œë ¥í•˜ì§€ ë§ ê²ƒ
- JSONì€ í•œ ì¤„ë¡œ(ì¤„ë°”ê¿ˆ ì—†ì´) ì¶œë ¥í•  ê²ƒ
- Format: <<UI>>{"type":"criteria_card","thinking":"...","criteria":["...","..."]}<<END_UI>>
3) ì•„ì§ ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ì§ˆë¬¸ë§Œ í•˜ê³  UI ë¸”ë¡ì€ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤.
4) thinkingì€ ìœ ì €ì—ê²Œì„œ ë°›ì€ ì •ë³´ë¥¼ ì´ìš©í•´ ì–´ë–¤ ì‚¬ëŒì„ ì°¾ì„ì§€ë¥¼ re-paraphraseí•œë‹¤. ê´€ë ¨ì—†ëŠ” ì •ë³´ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜, ì¤‘ìš”í•œ ì •ë³´ë¥¼ ë¹¼ë†“ì§€ ë§ê³ .

ì˜ˆì‹œ: ìœ ì €ê°€ "y combinator íˆ¬ìí•œ íšŒì‚¬ ëŒ€í‘œ, í•œêµ­ì¸"ì´ë¼ê³  í–ˆì„ ë•Œ,
{
  "thinking": "Y combinatorê°€ íˆ¬ìí•œ íšŒì‚¬ì˜ founderì´ì í•œêµ­ì¸ì„ ì°¾ìŠµë‹ˆë‹¤.",
  "criteria": ["Y combinator íˆ¬ìí•œ íšŒì‚¬ì˜ founderì¸ê°€", "í•œêµ­ì¸ì¸ê°€"]
}
`;

function sleep(ms: number) {
  return new Promise((r) => setTimeout(r, ms));
}

export async function POST(req: NextRequest) {
  if (req.method !== "POST") {
    return NextResponse.json({ error: "Method not allowed" }, { status: 405 });
  }

  const body = (await req.json()) as {
    model?: string;
    messages?: ChatMessage[];
  };

  const model = "grok-4-fast-non-reasoning";

  const messages = Array.isArray(body.messages) ? body.messages : [];
  if (!messages.length) {
    return NextResponse.json({ error: "Missing messages" }, { status: 400 });
  }

  // ì´ê±´ ì„ì˜ì˜ í•¨ìˆ˜ì…ë‹ˆë‹¤.
  const lastUser =
    [...messages].reverse().find((m) => m.role === "user")?.content ?? "";

  if (lastUser.includes("ì¡°ê±´")) {
    const shouldShowUI =
      lastUser.includes("ê²€ìƒ‰") ||
      lastUser.includes("ì°¾ì•„") ||
      lastUser.includes("ì‹¤í–‰");

    const TEXT_ONLY = `ì¢‹ì•„ìš”. ê²€ìƒ‰ ê¸°ì¤€ì„ ë§Œë“¤ê¸° ìœ„í•´ ëª‡ ê°€ì§€ë§Œ ë” ì•Œë ¤ì£¼ì„¸ìš”. ì–´ë–¤ ì§ë¬´ì¸ì§€, ê²½ë ¥, ì§€ì—­, í•„ìˆ˜ ìŠ¤í‚¬ì´ ìˆìœ¼ë©´ ì¢‹ì•„ìš”.`;
    const TEXT_WITH_UI = `ì¢‹ì•„ìš”. ã„±ã„±`;
    const UI_BLOCK = `<<UI>>{"type":"criteria_card","thinking":"ê¸°ë³¸ì ì¸ ê²€ìƒ‰ ì¡°ê±´ì´ ëª…í™•í•©ë‹ˆë‹¤.","criteria":["AI/ML ê´€ë ¨ ê²½ë ¥","í•œêµ­ ê·¼ë¬´ ê°€ëŠ¥","ìŠ¤íƒ€íŠ¸ì—… ê²½í—˜ ì„ í˜¸"],"ready":true}<<END_UI>>`;

    const fullText = shouldShowUI
      ? TEXT_WITH_UI + "\n" + UI_BLOCK + "\n ì´ê±°ë©´ ë˜ê² ì£ ?"
      : TEXT_ONLY;

    const encoder = new TextEncoder();

    const stream = new ReadableStream({
      async start(controller) {
        // ğŸ‘‰ ìŠ¤íŠ¸ë¦¬ë° í‰ë‚´ (ê¸€ì ë‹¨ìœ„ë¡œ ìª¼ê°¬)
        for (const ch of fullText) {
          controller.enqueue(encoder.encode(ch));
          await sleep(20); // ë„ˆë¬´ ëŠë¦¬ë©´ 5~10msë¡œ ì¤„ì—¬ë„ ë¨
        }
        controller.close();
      },
    });

    return new Response(stream, {
      headers: {
        "Content-Type": "text/plain; charset=utf-8",
        "Cache-Control": "no-cache",
      },
    });
    //
  }

  console.log("LLMì´ í˜¸ì¶œë©ë‹ˆë‹¤. ");
  const stream = await xaiClient.chat.completions.create({
    model,
    messages: [
      { role: "system", content: SYSTEM_PROMPT },
      ...messages.map((message) => ({
        role: message.role,
        content: message.content,
      })),
    ],
    temperature: 0.7,
    stream: true,
  });

  const encoder = new TextEncoder();
  const responseStream = new ReadableStream({
    async start(controller) {
      try {
        for await (const chunk of stream) {
          const delta = chunk.choices?.[0]?.delta?.content ?? "";
          if (delta) controller.enqueue(encoder.encode(delta));
        }
      } catch (error) {
        controller.error(error);
      } finally {
        controller.close();
      }
    },
  });

  return new Response(responseStream, {
    headers: {
      "Content-Type": "text/plain; charset=utf-8",
      "Cache-Control": "no-cache, no-transform",
      Connection: "keep-alive",
    },
  });
}
